{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/site-packages/pkg_resources/__init__.py:1146: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  self, resource_name\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/site-packages/patsy/constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/zeynepenkavi/anaconda/envs/py37/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import ActflowToolbox as actflow\n",
    "from nltools.utils import get_resource_path\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.data import Design_Matrix\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunzip: hcp_task.tgz: not in gzip format\n",
      "tar: Error opening archive: Unrecognized archive format\n"
     ]
    }
   ],
   "source": [
    "# thetarfile = \"https://osf.io/s4h8j/download/\"\n",
    "# ftpstream = urllib.request.urlopen(thetarfile)\n",
    "# thetarfile = tarfile.open(fileobj=ftpstream, mode=\"r|gz\")\n",
    "# thetarfile.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thetarfile = \"https://osf.io/bqp7m/download/\"\n",
    "# ftpstream = urllib.request.urlopen(thetarfile)\n",
    "# thetarfile = tarfile.open(fileobj=ftpstream, mode=\"r|gz\")\n",
    "# thetarfile.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data shared for NMA projects is a subset of the full HCP dataset\n",
    "N_SUBJECTS = 339\n",
    "\n",
    "# The data have already been aggregated into ROIs from the Glasesr parcellation\n",
    "N_PARCELS = 360\n",
    "\n",
    "# The acquisition parameters for all tasks were identical\n",
    "TR = 0.72  # Time resolution, in sec\n",
    "\n",
    "# The parcels are matched across hemispheres with the same order\n",
    "HEMIS = [\"Right\", \"Left\"]\n",
    "\n",
    "# Each experiment was repeated multiple times in each subject\n",
    "N_RUNS_REST = 4\n",
    "N_RUNS_TASK = 2\n",
    "\n",
    "# Time series data are organized by experiment, with each experiment\n",
    "# having an LR and RL (phase-encode direction) acquistion\n",
    "BOLD_NAMES = [\n",
    "  \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\",\n",
    "  \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
    "  \"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\",\n",
    "  \"tfMRI_WM_RL\", \"tfMRI_WM_LR\",\n",
    "  \"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\",\n",
    "  \"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\",\n",
    "  \"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\",\n",
    "  \"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\",\n",
    "  \"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"\n",
    "]\n",
    "\n",
    "#Task info dictionaries \n",
    "conditions_dict={\n",
    "    \"motor\": [\"cue\", \"rf\", \"lf\", \"rh\", \"lh\"],\n",
    "    \"wm\": [\"0bk_body\", \"0bk_faces\", \"0bk_places\", \"0bk_tools\", \"2bk_body\", \n",
    "           \"2bk_faces\", \"2bk_places\", \"2bk_tools\"],\n",
    "    \"emotion\": [\"fear\", \"neut\"],\n",
    "    \"gambling\": [\"win\", \"loss\"],\n",
    "    \"language\": [\"story\", \"math\"],\n",
    "    \"relational\": [\"match\", \"relation\"],\n",
    "    \"social\": [\"mental\", \"rnd\"]}\n",
    "\n",
    "run_length_dict = {\n",
    "    \"motor\": 284,\n",
    "    \"wm\": 405,\n",
    "    \"emotion\": 176,\n",
    "    \"gambling\": 253,\n",
    "    \"language\": 316,\n",
    "    \"relational\": 232,\n",
    "    \"social\": 274}\n",
    "\n",
    "bold_name_dict = {\n",
    "    \"rest\": [\"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\", \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\"],\n",
    "    \"motor\": [\"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\"],\n",
    "    \"wm\": [\"tfMRI_WM_RL\", \"tfMRI_WM_LR\"],\n",
    "    \"emotion\": [\"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\"],\n",
    "    \"gambling\": [\"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\"],\n",
    "    \"language\": [\"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\"],\n",
    "    \"relational\": [\"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\"],\n",
    "    \"social\": [\"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"]}\n",
    "\n",
    "task_run_dict = {\n",
    "    \"rest\": [1,2,3,4],\n",
    "    \"motor\": [5,6],\n",
    "    \"wm\": [7,8],\n",
    "    \"emotion\": [9,10],\n",
    "    \"gambling\": [11,12],\n",
    "    \"language\": [13, 14],\n",
    "    \"relational\": [15, 16],\n",
    "    \"social\": [17, 18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_evs(cond_name, task_name, subject, run = 1, hcp_task_dir = './hcp_task'):\n",
    "    \n",
    "    bold_name = bold_name_dict[task_name][run-1]\n",
    "    cond_evs = pd.read_csv('%s/subjects/%s/EVs/%s/%s.txt'%(hcp_task_dir, subject, bold_name, cond_name), sep=\"\\t\", header=None)\n",
    "    cond_evs = cond_evs.rename(columns={0: \"Onset\", 1: \"Duration\", 2: \"amplitude\"})\n",
    "    cond_evs = cond_evs.drop(columns=['amplitude'])\n",
    "    cond_evs['Stim'] = cond_name\n",
    "    \n",
    "    return cond_evs\n",
    "\n",
    "def get_run_evs(subject, task_name, run = 1):\n",
    "    \n",
    "    conditions = conditions_dict[task_name]\n",
    "    evs = pd.DataFrame()\n",
    "    for cond in conditions:\n",
    "        cond_evs = get_cond_evs(cond, task_name, subject, run)\n",
    "        evs = evs.append(cond_evs)\n",
    "    \n",
    "    evs = evs.sort_values(by=\"Onset\") \n",
    "    return evs\n",
    "\n",
    "def run_evs_to_dm(run_evs, task_name, TR=.72, convolve = True, add_poly = 2, dct_basis=False):\n",
    "\n",
    "    sampling_freq = 1./TR\n",
    "    run_length = run_length_dict[task_name]\n",
    "    dm = onsets_to_dm(run_evs, sampling_freq=sampling_freq, run_length=run_length, sort=True, add_poly=add_poly)\n",
    "    \n",
    "    if convolve: \n",
    "        dm = dm.convolve()\n",
    "    \n",
    "    if dct_basis:\n",
    "        dm = dm.add_dct_basis()\n",
    "\n",
    "    return dm\n",
    "\n",
    "def get_task_dms(subject, task_name, TR = .72, convolve = True, add_poly = 2, dct_basis=False):\n",
    "    \n",
    "    runs = list(range(1,len(task_run_dict[task_name])+1))\n",
    "    task_dm = Design_Matrix(sampling_freq=1./TR)\n",
    "    \n",
    "    for run in runs:\n",
    "        run_evs = get_run_evs(subject=subject, task_name=task_name, run=run)\n",
    "        run_dm = run_evs_to_dm(run_evs=run_evs, task_name=task_name, add_poly=add_poly, dct_basis=dct_basis)\n",
    "        task_dm = task_dm.append(run_dm)\n",
    "        \n",
    "    return task_dm\n",
    "\n",
    "def load_run_timeseries(subject, task_name, run = 1, remove_mean=True, scale_ts=True):\n",
    "    \n",
    "    bold_run = task_run_dict[task_name][run-1]\n",
    "    \n",
    "    if task_name == 'rest':\n",
    "        HCP_DIR = './hcp_rest'\n",
    "    else:\n",
    "        HCP_DIR='./hcp_task'\n",
    "\n",
    "    bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
    "    bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
    "    ts = np.load(f\"{bold_path}/{bold_file}\")\n",
    "    if remove_mean:\n",
    "        ts -= ts.mean(axis=1, keepdims=True)\n",
    "\n",
    "    if scale_ts:\n",
    "    #scales each parcel's timeseries (instead of scaling the bold for one 1 TR from all parcels)\n",
    "        ts = scale(ts, axis=1)\n",
    "    \n",
    "    return ts\n",
    "\n",
    "def load_task_timeseries(subject, task_name, remove_mean=True, scale_ts = True):\n",
    "  \n",
    "    runs = list(range(1,len(task_run_dict[task_name])+1))\n",
    "    task_ts = np.empty((360, 0))\n",
    "\n",
    "    for run in runs:\n",
    "    #since everything is loaded by run and scale_ts is true each parcel should be \n",
    "    #scaled for each parcel and for each run separately before being concatenated together\n",
    "        cur_run_ts = load_run_timeseries(subject=subject, task_name=task_name, run=run)\n",
    "        task_ts = np.append(task_ts, cur_run_ts, axis=1)\n",
    "  \n",
    "    return task_ts\n",
    "\n",
    "def get_sub_task_resids_and_preds(subject, task_name):\n",
    " \n",
    "    #load task data\n",
    "    task_ts = load_task_timeseries(subject=subject, task_name=task_name)\n",
    "\n",
    "    #make design matrix\n",
    "    task_dm = get_task_dms(subject=subject, task_name=task_name)\n",
    "    task_regs = task_dm.iloc[:,:len(conditions_dict[task_name])]\n",
    "\n",
    "    #initialize empty variables to store data in\n",
    "    run_length = run_length_dict[task_name]\n",
    "    num_runs = len(task_run_dict[task_name])\n",
    "    resids = np.empty((0, num_runs*run_length))\n",
    "    preds = np.empty((0, num_runs*run_length))\n",
    "\n",
    "    #loop through parcels, run regression and extract residuals\n",
    "    for parcel in range(len(task_ts)):\n",
    "        model = sm.OLS(task_ts[parcel], task_dm)\n",
    "        results = model.fit()\n",
    "    \n",
    "        cur_resids = np.array([results.resid])\n",
    "        resids = np.append(resids, cur_resids, axis=0)\n",
    "    \n",
    "        task_coefs = results.params[:len(conditions_dict[task_name])]\n",
    "        cur_preds = np.zeros(num_runs*run_length)\n",
    "        for i in range(len(conditions_dict[task_name])):\n",
    "            cur_preds += task_coefs[i]*task_regs.iloc[:,i]\n",
    "        cur_preds = np.array(cur_preds).reshape(1, -1)\n",
    "        preds = np.append(preds, cur_preds, axis=0)\n",
    "\n",
    "    #save task residuals\n",
    "    out_dir = './output/residuals/%s'%(task_name)\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    out_fn = '%s_%s_Glasser360Cortical.npy'%(task_name, str(subject))\n",
    "    np.save(os.path.join(out_dir, out_fn), resids)\n",
    "\n",
    "    #save task predictions\n",
    "    out_dir = './output/task_preds/%s'%(task_name)\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    out_fn = '%s_%s_Glasser360Cortical.npy'%(task_name, str(subject))\n",
    "    np.save(os.path.join(out_dir, out_fn), preds)\n",
    "    \n",
    "    return resids, preds\n",
    "\n",
    "def get_sub_fc(subject, task_name, fc_type, base_dir = './output'):\n",
    "    \n",
    "    if fc_type == \"residual\":\n",
    "        ts_dir = os.path.join(base_dir, 'residuals')\n",
    "        fc_dir = os.path.join(base_dir, 'residual_fcs')\n",
    "  \n",
    "    elif fc_type == \"task_preds\":\n",
    "        ts_dir = os.path.join(base_dir, 'task_preds')\n",
    "        fc_dir = os.path.join(base_dir, 'task_preds_fcs')\n",
    "\n",
    "    elif fc_type == \"rest\":\n",
    "        fc_dir = os.path.join(base_dir, 'rest_fcs')\n",
    "    \n",
    "    if not os.path.exists(fc_dir):\n",
    "        os.makedirs(fc_dir)\n",
    "        \n",
    "    if task_name != 'rest':\n",
    "        ts = np.load(os.path.join(ts_dir, task_name, task_name+'_'+subject+'_Glasser360Cortical.npy'))\n",
    "    else:\n",
    "        ts = load_task_timeseries(subject=subject, task_name=task_name)\n",
    "    \n",
    "    sub_fc = np.corrcoef(ts)\n",
    "    out_fn = '%s_%s_%s_fc.npy'%(task_name, str(subject), fc_type)\n",
    "    np.save(os.path.join(fc_dir, out_fn), sub_fc)\n",
    "\n",
    "    return sub_fc\n",
    "\n",
    "def load_fcs(task_name, fc_type, base_dir = './output'):\n",
    "    \n",
    "    if fc_type == \"residual\":\n",
    "        fc_dir = os.path.join(base_dir, 'residual_fcs')\n",
    "  \n",
    "    elif fc_type == \"task_preds\":\n",
    "        fc_dir = os.path.join(base_dir, 'task_preds_fcs')\n",
    "\n",
    "    elif fc_type == \"rest\":\n",
    "        fc_dir = os.path.join(base_dir, 'rest_fcs')\n",
    "\n",
    "    input_dir = os.path.join(fc_dir, task_name)\n",
    "    fcs_list = os.listdir(input_dir)\n",
    "    fcs = np.zeros((360, 360, len(fcs_list)))\n",
    "\n",
    "    for i, fc in enumerate(fcs_list):\n",
    "        fcs[:,:,i] = np.load(os.path.join(input_dir, fc))\n",
    "\n",
    "    return fcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
    "regions = np.load('./hcp_task/regions.npy').T\n",
    "region_info = dict(\n",
    "    name=regions[0].tolist(),\n",
    "    network=regions[1],\n",
    "    myelin=regions[2].astype(np.float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "networkpartition_dir = pkg_resources.resource_filename('ActflowToolbox.dependencies', 'ColeAnticevicNetPartition/')\n",
    "networkdef = np.loadtxt(networkpartition_dir + '/cortex_parcel_network_assignments.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "netorder=networkorder[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "network_dict = {1: 'Visual1', \n",
    "       2: 'Visual2', \n",
    "       3:'Somatomotor',\n",
    "       4:'Cingulo-Oper',\n",
    "       5:'Language',\n",
    "       6:'Default',\n",
    "       7:'Frontopariet',\n",
    "       8:'Auditory',\n",
    "       9:'Posterior-Mu',\n",
    "       10:'Dorsal-atten',\n",
    "       11:'Ventral-Mult',\n",
    "       12:'Orbito-Affec'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['135', '307', '61', '95', '338', '300', '132', '59', '92', '66']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = os.listdir('./hcp_task/subjects')\n",
    "subjects = [i for i in subjects if i.startswith('.') == False]\n",
    "subjects[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_names = [\"emotion\", \"motor\", \"gambling\"]\n",
    "# for task_name in task_names:\n",
    "#   print(\"Starting residual calculations for task_name: %s\"%(task_name))\n",
    "#   for subject in subjects:\n",
    "#     sub_res, sub_pred = get_sub_task_resids_and_preds(subject = subject, task_name=task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC for rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = os.listdir('./hcp_rest/subjects')\n",
    "# subjects = [i for i in subjects if i.startswith('.') == False]\n",
    "# for subject in subjects:\n",
    "#     sub_res = get_sub_fc(subject = subject, task_name=\"rest\", fc_type=\"rest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC for task predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_names = [\"emotion\", \"motor\", \"gambling\"]\n",
    "# for task_name in task_names:\n",
    "#     for subject in subjects:\n",
    "#         sub_res = get_sub_fc(subject = subject, task_name=task_name, fc_type=\"task_preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC for residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for task_name in task_names:\n",
    "#     for subject in subjects:\n",
    "#         sub_res = get_sub_fc(subject = subject, task_name=task_name, fc_type=\"residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC comparison figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_fcs = {}\n",
    "task_names = [\"emotion\", \"motor\", \"gambling\"]\n",
    "for task_name in task_names:\n",
    "  print(\"Loading resid FC for: %s\"%(task_name))\n",
    "  resid_fcs[task_name] = load_fcs(task_name, fc_type='resid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_fcs_ave = {}\n",
    "for task_name in task_names:\n",
    "  print(\"Averaging resid FCs for: %s\"%(task_name))\n",
    "  cur_task_fcs = resid_fcs[task_name]\n",
    "  resid_fcs_ave[task_name] = np.mean(cur_task_fcs[netorder,:,:][:,netorder,:],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir = '/content/drive/My Drive/Colab Notebooks/fc_plots'\n",
    "# if not os.path.exists(out_dir):\n",
    "#   os.makedirs(out_dir)\n",
    "# for i, task_name in enumerate(task_names):\n",
    "#   fig = actflow.tools.addNetColors_Seaborn(resid_fcs_ave[task_name])\n",
    "#   figFileName = '%s_resid_fc.png'%(task_name)\n",
    "#   fig.savefig(os.path.join(out_dir, figFileName), bbox_inches='tight', format='png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_fcs = load_fcs(task_name=\"rest\", fc_type=\"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_fcs_ave = np.mean(rest_fcs[netorder,:,:][:,netorder,:],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_pred_fcs = {}\n",
    "task_names = [\"emotion\", \"motor\", \"gambling\"]\n",
    "for task_name in task_names:\n",
    "  print(\"Loading resid FC for: %s\"%(task_name))\n",
    "  task_pred_fcs[task_name] = load_fcs(task_name, fc_type='task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_pred_fcs_ave = {}\n",
    "for task_name in task_names:\n",
    "  print(\"Averaging resid FCs for: %s\"%(task_name))\n",
    "  cur_task_fcs = task_pred_fcs[task_name]\n",
    "  task_pred_fcs_ave[task_name] = np.mean(cur_task_fcs[netorder,:,:][:,netorder,:],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/content/drive/My Drive/Colab Notebooks/fc_plots'\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)\n",
    "for i, task_name in enumerate(task_names):\n",
    "  fig = actflow.tools.addNetColors_Seaborn(task_pred_fcs_ave[task_name])\n",
    "  figFileName = '%s_task_fc.png'%(task_name)\n",
    "  fig.savefig(os.path.join(out_dir, figFileName), bbox_inches='tight', format='png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"][0] = 18\n",
    "plt.rcParams[\"figure.figsize\"][1] = 15\n",
    "\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "ax = ax.flatten()\n",
    "ax = ax[:7]\n",
    "fig_dir = '/content/drive/My Drive/Colab Notebooks/fc_plots/'\n",
    "\n",
    "task_names = ['emotion_resid', 'motor_resid', 'gambling_resid', 'emotion_task', 'motor_task', 'gambling_task',\"rest\"]\n",
    "\n",
    "for a, task_name in zip(ax, task_names):\n",
    "  tmp = mpimg.imread(os.path.join(fig_dir, '%s_fc.png'%(task_name)))\n",
    "  a.set_title(task_name)\n",
    "  a.axis('off')\n",
    "  a.imshow(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
